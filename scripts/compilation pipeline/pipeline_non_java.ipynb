{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains the complete step-wise filter, pull, and SonarQube analysis pipeline for the provided git repositories.  \n",
    "The expected input is a list of repositories of which the data is acquired through the github web API.\n",
    "\n",
    "Make sure that a SonarQube instance is running prior to running this script and that the credentials used in the analysis phase are set correctly.\n",
    "Consider that executing this script takes quite a while to complete.\n",
    "\n",
    "- SonarQube logs are put in the `./output` folder, you can use this to figure out why SonarQube fails when analyzing certain projects.\n",
    "- The results are put in the `./results` folder.\n",
    "\n",
    "If you interrupt this script halfway through, or the script crashes at some point, it might be that it doesn't work the next run.\n",
    "Restarting Jupyter might help here, but also check if the access tokens are revoked correctly.\n",
    "Additionally, at some point the SonarQube might run out of heap memory, which is why this script is executed in batches, each of which has a corresponding sonarqube instance.\n",
    "\n",
    "This script uses bash calls to run SonarQube, so if you run this on Windows, these commands probably have to be changed somewhat.\n",
    "It's definitely not perfect either; it is quite likely it will crash a few times whilst running it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data:\n",
      "[['trafficserver', 'https://github.com/apache/trafficserver', '132898', 'master', 'C++']]\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "import os\n",
    "import requests\n",
    "from git import Repo, GitCommandError\n",
    "import subprocess\n",
    "from typing import Tuple\n",
    "import shutil\n",
    "from subprocess import Popen\n",
    "import time\n",
    "\n",
    "with open(\"./data/test_repositories.csv\", \"r\") as data_file:\n",
    "    data = [entry.strip().split(\",\") for entry in data_file.readlines()[1:]]\n",
    "\n",
    "print(f'loaded data:\\n{data}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 of the lifecycle, all methods used to statically filter the repositories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_TYPE = 4\n",
    "\n",
    "\n",
    "def is_not_java(entry: array) -> bool:\n",
    "    return entry[PROJECT_TYPE] != \"Java\"\n",
    "\n",
    "\n",
    "def is_considered(entry: array) -> bool:\n",
    "    \"\"\"Returns true if the project is a maven project\"\"\"\n",
    "\n",
    "    # return is_java(entry) and is_maven(entry)\n",
    "    return is_not_java(entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 of the lifecycle, cloning a repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 0\n",
    "PROJECT_REPO_URL = 1\n",
    "DEFAULT_BRANCH = 3\n",
    "\n",
    "date = \"May 7, 2020\"\n",
    "\n",
    "\n",
    "def clone_repository(entry: array) -> Tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Clones repository to the ./repos folder and \n",
    "    returns the status code and repo's folder.\n",
    "    \"\"\"\n",
    "\n",
    "    url = entry[PROJECT_REPO_URL]\n",
    "    dir = os.path.join(\"./repos\", entry[PROJECT_NAME])\n",
    "\n",
    "    try:\n",
    "        Repo.clone_from(url, dir)\n",
    "        status = 0\n",
    "\n",
    "    except GitCommandError as e:\n",
    "        if e.status != 128:\n",
    "            status = e.status\n",
    "        else:\n",
    "            status = 0\n",
    "            print(f'repository for {entry[PROJECT_NAME]} is already cloned')\n",
    "\n",
    "    finally:\n",
    "        return status, dir\n",
    "\n",
    "\n",
    "def checkout_date(dir: str, entry: array):\n",
    "    \"\"\"Checks out the latest version of the default branch at the given time.\"\"\"\n",
    "\n",
    "    os.chdir(dir)\n",
    "\n",
    "    args = [f'git rev-list -1 --before=\"{date}\" {entry[DEFAULT_BRANCH]}']\n",
    "    with Popen(args, stdout=subprocess.PIPE, stderr=None, shell=True) as get_commit:\n",
    "        commit = get_commit.stdout.read().decode('UTF-8')\n",
    "\n",
    "    args = [f'git checkout {commit}']\n",
    "    with Popen(args, stdout=subprocess.PIPE, stderr=None, shell=True) as do_checkout: \n",
    "        status = do_checkout.returncode\n",
    "\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "    return status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements steps 3 to 5 of the lifecycle, the SonarQube steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url = \"http://sonarqube:9000\"\n",
    "auth = ('admin', 'password')\n",
    "\n",
    "\n",
    "def create_sonarqube_project(entry: array) -> int:\n",
    "    \"\"\"Creates SonarQube project if none exists yet\"\"\"\n",
    "\n",
    "    name = entry[PROJECT_NAME]\n",
    "\n",
    "    url = f\"{server_url}/api/projects/create\"\n",
    "    data = {'name': name, 'project': name, 'visibility': 'public'}\n",
    "    c_res = requests.post(url=url, data=data, auth=auth)\n",
    "\n",
    "    return c_res.status_code\n",
    "\n",
    "\n",
    "def perform_sonarqube_analysis(entry: array, dir: str) -> int:\n",
    "    \"\"\"Executes sonarqube analaysis and sends it to the server\"\"\"\n",
    "\n",
    "    name = entry[PROJECT_NAME]\n",
    "\n",
    "    # All java files are ignored as they require compiling and\n",
    "    # will cause the analysis to fail.\n",
    "    args = [\n",
    "        'sonar-scanner',\n",
    "        '-Dsonar.sources=.',\n",
    "        f'-Dsonar.projectKey={name}',\n",
    "        f'-Dsonar.host.url={server_url}',\n",
    "        f'-Dsonar.login={auth[0]}',\n",
    "        f'-Dsonar.password={auth[1]}',\n",
    "        '-Dsonar.coverage.exclusions=/**.java',\n",
    "        '-Dsonar.test.exclusions=/**.java',\n",
    "        '-Dsonar.exclusions=/**.java'\n",
    "    ]\n",
    "\n",
    "    with open(f\"./output/{name}-sonarqube-output.log\", \"w\") as output_file:\n",
    "        os.chdir(dir)\n",
    "        res = subprocess.run(args, stdout=output_file)\n",
    "\n",
    "    # TODO: this shouldn't assume two layers.\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "    return res.returncode\n",
    "\n",
    "\n",
    "def export_sonarqube_issues(entry: array):\n",
    "    \"\"\"Exports the generated issues through the web API\"\"\"\n",
    "\n",
    "    name = entry[PROJECT_NAME]\n",
    "\n",
    "    url = f\"{server_url}/api/issues/search\"\n",
    "    data = {'componentKeys': name}\n",
    "    res = requests.get(url=url, data=data, auth=auth)\n",
    "\n",
    "    with open(f\"./results/issues-{name}.json\", \"w\") as results_file:\n",
    "        results_file.write(res.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 of the lifecycle, clean up methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sonarqube_project(entry: array):\n",
    "    \"\"\"Deletes sonarqube project \"\"\"\n",
    "\n",
    "    name = entry[PROJECT_NAME]\n",
    "\n",
    "    url = f'{server_url}/api/projects/delete'\n",
    "    data = {'project': name}\n",
    "    requests.post(url=url, data=data, auth=auth)\n",
    "\n",
    "\n",
    "def delete_repository(entry, dir):\n",
    "    \"\"\"Deletes repository\"\"\"\n",
    "\n",
    "    shutil.rmtree(dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements the pipeline lifecycle.\n",
    "\n",
    "1. filtering repositories\n",
    "2. cloning repositories\n",
    "3. creating SonarQube project\n",
    "4. analyzing repository\n",
    "5. exporting results\n",
    "6. (optional) deleting sonarqube project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving repository of trafficserver\n",
      "repository for trafficserver is already cloned\n",
      "checking out at date for trafficserver\n",
      "creating project for trafficserver\n",
      "creating project failed for trafficserver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD is now at ad89f720f Fix typos in comments\n"
     ]
    }
   ],
   "source": [
    "def perform_lifecycle(entry: array):\n",
    "\n",
    "    name = entry[PROJECT_NAME]\n",
    "\n",
    "    # step 1: filtering\n",
    "    if not is_considered(entry):\n",
    "        print(f\"filtered out {name}.\")\n",
    "        return\n",
    "\n",
    "    # step 2: cloning repositories.\n",
    "    print(f'retrieving repository of {name}')\n",
    "    status, dir = clone_repository(entry)\n",
    "    if status != 0:\n",
    "        print(f'cloning repository failed for {name} with status {status}')\n",
    "        return\n",
    "\n",
    "    time.sleep(1)\n",
    "    # step 2a: checking out at date.\n",
    "    print(f'checking out at date for {name}')\n",
    "    checkout_date(dir, entry)\n",
    "\n",
    "    # step 3: creating sonarqube project\n",
    "    print(f'creating project for {name}')\n",
    "    status = create_sonarqube_project(entry)\n",
    "    if status != 200:\n",
    "        print(f'creating project failed for {name}')\n",
    "        return\n",
    "\n",
    "    # step 4: running SonarQube\n",
    "    print(f'running sonarqube on {name}')\n",
    "    status = perform_sonarqube_analysis(entry, dir)\n",
    "    if status != 0:\n",
    "        print(f'sonarqube analysis failed for {name} with status {status}')\n",
    "    else:\n",
    "        # step 5: extracting sonarqube data\n",
    "        print(f'exporting results of {name}')\n",
    "        export_sonarqube_issues(entry)\n",
    "\n",
    "    # step 6: deleting sonarqube project\n",
    "    print(f'cleaning up after {name}')\n",
    "    # delete_sonarqube_project(entry)\n",
    "    # delete_repository(entry, dir)\n",
    "\n",
    "    print(f'completed analysis on {name}')\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    perform_lifecycle(entry)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
